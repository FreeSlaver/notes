* 漫画网站搭建
  感觉市面上有非常好的漫画网站了。

  首先想想，如何来做，主要是有首页，然后按字母排序，热门分类，最新分类等。
  可以搜索，然后

  漫画分类，移动版适配，
  漫画翻页如何实现，

  设为桌面图标，添加到搜藏夹，添加到百度首页，分享怎么实现？

  别人可以，我也可以，1T流量等于1024G，除以2等于512，也就是512个人
  看完火影，

  现在的问题是点点击之后，跳转到下一页。

  现在要做的是：
  1. 将海贼王的所有漫画搞到vps上
     如何使用aria2下载磁力链接

  2. 哪里接广告


  搞个域名

  还是坚持将这个搞完。
*** DONE 单页面的生成
    CLOSED: [2019-01-17 Thu 10:11]
    :LOGBOOK:
    - State "DONE"       from "TODO"       [2019-01-17 Thu 10:11]
    :END:
*** DONE 漫画网站seo
    CLOSED: [2019-01-17 Thu 11:41]
    :LOGBOOK:
    - State "DONE"       from "TODO"       [2019-01-17 Thu 11:41]
    :END:
    主要是tags，keywords，description的描写
    这个肯定是根据每个漫画来搞的，比如火影忍者的，海贼王的不一样，

    tags： 火影忍者,naruto,日漫,傅人传,acg,漫画,在线免费
    keywords: 火影忍者,傅人传,漫画,acg,在线免费
    description:火影忍者漫画是由岸本齐史创作，讲述的是一个叫漩涡鸣人的从小体内就被封印了尾兽九尾妖狐，
    和拥有血轮眼但被灭族的幸存者宇智波佐助的成长故事，网站提供在线免费观看的服务，包括剧场版，
    分集剧情，黄漫，福利图禁图等ppt，pdf格式

    对，有个关键字搜索的网站，
    然后讲keywords组合成description，最好是造个句子吧。
    这个其实很关键，而且那么长的漫画，但是这个关键字，描述等等都是一样的。
    先想想所有的关键字，然后从中过滤出关键的几个，然后造句。

    关键字的组合，
    火影忍者，ol，博人传，漫画，本子，acg，库番全彩，博人传漫画，
    壁纸，免费，观看，剧场版，动漫，全集，动画片，分集剧情，
    黄漫，纲手，福利图，游戏，在线，女忍者禁图，ppt？pdf，全集，百度网盘，
    jump，热血动漫，集英社，naruto，漩涡鸣人，宇智波佐助，九尾妖狐，
    木叶，忍者，小樱，宇智波鼬，卡卡西，忍界大战，写轮眼，岸本齐史，日本，
    中忍考试，大蛇丸，晓组织，尾兽，螺旋丸，岁图转生，

    不对，每部漫画都要加上这个得多费时间啊？
    先把这个网站先搞上去再说，不过已经搞了

    坚决不去上班，一群JB人，烦得要死。
*** DONE 网站图片到nginx的映射，还有那个nginx的图片优化
    CLOSED: [2019-01-17 Thu 16:13]
    :LOGBOOK:
    - State "DONE"       from "TODO"       [2019-01-17 Thu 16:13]
    :END:
*** TODO 单页上还要加上那个多少页的下拉框，还有那个上一页，下一页
*** TODO 自动化程序
    这个建立目录最好也用程序的方式吧，也就是全部的流程，全部用编程的方式。

    首先指定目录，也就是_posts目录，之后创建hyrz这个目录，再遍历linux上的目录，
    或者指定一个数量，创建对于的子目录，

    程序解决的是重复性的劳动，想想量最大的是那些劳动？？？
    找到问题的关键点了。
    1. 创建目录，火影忍者有700多话，要搞700下，
       一定要创建吗？未必吧？可以通过指定子目录来解决，但是文件名了？加上第多少话就好了。
       但是创建目录明显更加好管理，但是需要管理吗？文件都是按照顺序排列的。
       但是文件的命名这个会显示到url上面，还是创建目录好，遍历看看有多少个子目录

    2. 每话里面的每个图片都要搞个页面
       差不多每话有个50页，搞50下？

    3. 问题
       是创建一个子目录，然后开始生成页面，还是统一先建立目录，然后再生成页面？
       先搞子目录要好。



*** TODO 加上拒绝adblock的js
*** TODO 对啊，我真够傻逼的，网上有各种动漫网站啊，可以直接把url给抓下来
    url放到哪里？放到mysql？还是直接写死？
    直接写死的花，后面链接失效，需要大规模

    对啊，TM的我真够傻逼的，而且有这么多漫画，
    用爬虫，然后后续更新，用程序，

    还是使用静态页面的方式，然后好好研究下jekyll的那个data，
    然后将所有数据放到data或者json之类的文件里面。

    页面的生成很简单，使用那个java工具就行了，
    但是这么多漫画，一个个搞吗？

    其实一个个搞，也废不了多少时间，热门的漫画就行了，关键是资源速度，
    还有哪些没有被防盗链的网站，
    1. 没有防盗链
    2. 图片的url比较规则，这样的话直接写程序就能生成了，而不用爬虫
    3. 使用jekyll的data来存储，一个漫画一个文件这样？
       是用json还是用yarm？肯定不是cvs，其实最关键的只需要图片的url，
       那么保存成txt也行，

    找到的几个资源网站有：
    http://www.cartoonmad.com/cartoonimg/e266ue51vd6/1029/685/004.jpg

    https://img.acgn.cc/img/400/340/5.jpg

    tool.chinaz.com可以测速比较
    只找到google前面的2个网站，cartonman比acgn要慢很多啊，
    而且cartonman的话少，卷多，蛋疼的很，发现啥都是那么容易的事情，

    现在就来生成页面，

    根据acgn先来搞页面吧
    先拿到这个页面的所有话，然后在看缺少的，
    直接将这个页面上的li全部搞下来，然后处理，得到链接，多少话，还有那个view，
    对应到后面的url，这样就得到所有的第几话的url，

    现在要防止的问题是：如果这个网站倒闭了，或者防止盗链了，怎么搞？
    那样就只能重新生成页面了，应为页面的url用不了了。用jekyll的好处是静态页面的模板什么
    的都搞好了，只需要填充内容就行。

    嗯，很简单，而且抓取也很容易，就这个网站吧。
    这个风之动漫肯定是对那个图片的地址做了个hash之类的处理。
    可以。
    还是的用那个jsoup来搞出来，主要信息是view-630，火影忍者494话，都不是规律的，
630需要，494也有，手动来一个个搞？妈的，疯了，蛋疼的很啊，

把那个卷和话先分开吧！

现在做到哪里了？实在是不想复习，也不想找工作，更不想看到那群逼人的一副嘴脸。

有个问题 ，阳光电源这种为何逆大势而动了？

* MapReduce核心概念理解                                                         :MapReduce:Concept:

  MapReduce其实是2个单词Map和Reduce。
  Map单词的本意是地图：我们拿出地图，找到一个地点，然后我们就知道去这个地点的路径了。
  也就是：起始点->路径（->表示映射）。
  Map做的就是：对一个对象进行一个操作。
  Reduce单词本意是减少，归纳，使xx分解。
  Reduce就是将Map操作后得到的结果进行合并，归类，

  那么MapReduce会处理很多个维度的东西。
  比如现在中国20亿人，针对每个人进行一项操作，这个就是Map，然后得到一个人的
  年龄，性别，身高，职业，学历，收入等。
  然后Reduce阶段，输出比如20到30岁的人占比，学历的占比，学历和收入的相关性等。


  是一个编程范式，为了大量杂乱的，扩展的数据
  是两个独立和分开的操作。

  The first is the map job, which takes a set of data and converts it into another set of data, where individual elements are broken down into tuples (key/value pairs).
  The reduce job takes the output from a map as input and combines those data tuples into a smaller set of tuples.


  Using the MapReduce framework, we can break this down into five map tasks, where each mapper works on one of the five files and the mapper task goes through the data and returns the maximum temperature for each city.

  All five of these output streams would be fed into the reduce tasks, which combine the input results and output a single value for each city, producing a final result set as follows:

  當前的軟體實現是指定一個Map（映射）函數，用來把一組鍵值對映射成一組新的鍵值對，指定並發的Reduce（化簡）函數，用來保證所有映射的鍵值對中的每一個共享相同的鍵組。

  MapReduce程式的執行過程如下：
將要執行的MapReduce程式複製到Master與每一個Worker機器中。
Master決定Map程式與Reduce程式，分別由哪些Worker機器執行。
將所有的資料區塊，分配到執行Map程式的Worker機器中進行Map。
將Map後的結果存入Worker機器的本地磁碟。
執行Reduce程式的Worker機器，遠端讀取每一份Map結果，進行彙整與排序，同時執行Reduce程式。
將使用者需要的運算結果輸出。


举个我们现实项目中的例子：
我们用户数有几千万，然后看那些用户是活跃的。
这边的傻逼做法，或者说传统做法是：将几千万用户的数据存到关系数据库或者es里，
然后使用一条查询语句：select * from user where active=true。这个我们都知道。

但是MapReduce的做法是：
将几千万用户数据分摊到几台机器上，然后对用户进行Map操作，取出唯一表示用户的字段，
加上是否活跃，也就是key:唯一标识，value:是否活跃。
然后Reduce阶段是对所有用户进行汇总，去重，得到符合条件（活跃的）用户数。

传统数据库的问题是单台机器无法承载这样的数据量，而且一台机器上对几千万的数据
进行操作，内存肯定不够。

映射阶段就是，通过数据得到我们想要的东西，我们想要的就是那个value。
https://cdn.guru99.com/images/Big_Data/061114_0930_Introductio1.png


MapReduce怎么组织工作
How MapReduce Organizes Work?
Hadoop divides the job into tasks. There are two types of tasks:

Map tasks (Spilts & Mapping)
Reduce tasks (Shuffling, Reducing)
as mentioned above.

The complete execution process (execution of Map and Reduce tasks, both) is controlled by two types of entities called a

Jobtracker : Acts like a master (responsible for complete execution of submitted job)
Multiple Task Trackers : Acts like slaves, each of them performing the job
For every job submitted for execution in the system, there is one Jobtracker that resides on Namenode and there are multiple tasktrackers which reside on Datanode.

What is MapReduce?  How it Works -  Hadoop MapReduce Tutorial

A job is divided into multiple tasks which are then run onto multiple data nodes in a cluster.
It is the responsibility of jobtracker to coordinate the activity by scheduling tasks to run on different data nodes.
Execution of individual task is then look after by tasktracker, which resides on every data node executing part of the job.
Tasktracker's responsibility is to send the progress report to the jobtracker.
In addition, tasktracker periodically sends 'heartbeat' signal to the Jobtracker so as to notify him of current state of the system.
Thus jobtracker keeps track of overall progress of each job. In the event of task failure, the jobtracker can reschedule it on a different tasktracker.




https://cdn.guru99.com/images/Big_Data/061114_0930_Introductio2.png

MapReduce包含四个组成部分，分别为Client、JobTracker、TaskTracker和Task，下面我们详细介绍这四个组成部分。
　　 1）Client 客户端
　　 每一个 Job 都会在用户端通过 Client 类将应用程序以及配置参数 Configuration 打包成 JAR 文件存储在 HDFS，并把路径提交到 JobTracker 的 master 服务，然后由 master 创建每一个 Task（即 MapTask 和 ReduceTask） 将它们分发到各个 TaskTracker 服务中去执行。

　　 2）JobTracker
　　JobTracke负责资源监控和作业调度。JobTracker 监控所有TaskTracker 与job的健康状况，一旦发现失败，就将相应的任务转移到其他节点；同时，JobTracker 会跟踪任务的执行进度、资源使用量等信息，并将这些信息告诉任务调度器，而调度器会在资源出现空闲时，选择合适的任务使用这些资源。在Hadoop 中，任务调度器是一个可插拔的模块，用户可以根据自己的需要设计相应的调度器。
　　
　　 3）TaskTracker
　　TaskTracker 会周期性地通过Heartbeat 将本节点上资源的使用情况和任务的运行进度汇报给JobTracker，同时接收JobTracker 发送过来的命令并执行相应的操作（如启动新任务、杀死任务等）。TaskTracker 使用“slot”等量划分本节点上的资源量。“slot”代表计算资源（CPU、内存等）。一个Task 获取到一个slot 后才有机会运行，而Hadoop 调度器的作用就是将各个TaskTracker 上的空闲slot 分配给Task 使用。slot 分为Map slot 和Reduce slot 两种，分别供Map Task 和Reduce Task 使用。TaskTracker 通过slot 数目（可配置参数）限定Task 的并发度。

　　 4）Task
　　 Task 分为Map Task 和Reduce Task 两种，均由TaskTracker 启动。HDFS 以固定大小的block 为基本单位存储数据，而对于MapReduce 而言，其处理单位是split。
　　 Map Task 执行过程如下图 所示：由该图可知，Map Task 先将对应的split 迭代解析成一个个key/value 对，依次调用用户 自定义的map() 函数进行处理，最终将临时结果存放到本地磁盘上, 其中临时数据被分成若干个partition，每个partition 将被一个Reduce Task 处理。

*** 论文
    Users specify a map function that processes a
key/valuepair to generate a set of intermediatekey/value
pairs, and a reduce function that merges all intermediate
values associated with the same intermediate key

 The run-time system takes care of the
details of partitioning the input data, scheduling the pro-
gram’s execution across a set of machines, handling ma-
chine failures, and managing the required inter-machine
communication.

 The issues of how to par-
allelize the computation, distribute the data, and handle
failures conspire to obscure the original simple compu-
tation with large amounts of complex code to deal with
these issues.

 hides the messy de-
tails of parallelization, fault-tolerance, data distribution
and load balancing in a library

Our abstraction is in-
spired by the map and reduce primitives present in Lisp
and many other functional languages


We realized that
most of our computations involved applying a map op-
eration to each logical “record” in our input in order to
compute a set of intermediate key/value pairs, and then
applying a reduce operation to all the values that shared
the same key, in order to combine the derived data ap-
propriately.

第九页
Our partitioningfunction


*** Tuple
    key-value键值对，但是这个东西可以多个Tuple进行聚合。
    也就是说将任何数量级，复杂的数据结构对分解成了key-value键值对。


** 参考
   [[http://blog.jobbole.com/1321/][我是如何向老婆解释MapReduce的？]]
   强烈推荐[[https://www.ibm.com/analytics/us/en/technology/hadoop/mapreduce/][： What is MapReduce? – IBM Analytics]]
   建议看最后一部分：[[https://www.guru99.com/introduction-to-mapreduce.html][What is MapReduce? How it Works - Hadoop MapReduce Tutorial]]
   强烈推荐，Google论文：[[https://static.googleusercontent.com/media/research.google.com/zh-CN//archive/mapreduce-osdi04.pdf][MapReduce: Simplified Data Processing on Large Clusters]]

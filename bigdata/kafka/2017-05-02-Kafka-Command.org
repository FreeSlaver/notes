* Kafka常用命令
压测集群地址：10.45.130.186:2181,10.45.130.187:2181,10.45.130.189:2181
腾讯云测试集群地址：node2:9092,10.33.2.9:9092,10.33.1.13:9092
生产集群地址：10.33.2.228:9090,10.33.2.71:9090,10.33.2.185:9090,10.33.2.91:9090,10.33.2.63:9090

新测试环境的集群 node2:2181,
注意点：妈的，一定要用配置在配置文件中的node2，ip等。
** 启动kafka
JMX_PORT=9997  bin/kafka-server-start.sh config/server.properties &

** 关闭kafka
bin/kafka-server-start.sh config/server.properties &
** Topic
*** 建立Topic
bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 6 --topic my-replicated-test

*** 删除Topic
慎用，只会删除zookeeper中的元数据，数据文件需手动删除（可能需要去zk上手动用rmr命令强制删除，delete命令不行）
bin/kafka-topics.sh --delete --zookeeper 10.45.130.186:2181,10.45.130.187:2181,10.45.130.189:2181 --topic esb.topic
bin/kafka-topics.sh --delete --zookeeper node2:2181 --topic api-exception,estation-test,my-topic,_consumer_offsets

*** 命令查看Topic
bin/kafka-topics.sh --list --zookeeper localhost:2181
bin/kafka-topics.sh --list --zookeeper 10.33.2.228:2181,10.33.2.91:2181,10.33.2.63:2181

*** 查看主题详情
bin/kafka-topics.sh --describe --zookeeper 10.33.2.228:2181,10.33.2.91:2181,10.33.2.63:2181 --topic estation-parcel

*** 手动均衡Topic
bin/kafka-preferred-replica-election.sh --zookeeper 192.168.197.170:2181,192.168.197.171:2181 --path-to-json-file preferred-click.json
cat preferred-click.json
{
 "partitions":
  [
  {"topic": "click", "partition": 0},
  {"topic": "click", "partition": 1},
  {"topic": "click", "partition": 2},
  {"topic": "click", "partition": 3},
  {"topic": "click", "partition": 4},
  {"topic": "click", "partition": 5},
  {"topic": "click", "partition": 6},
  {"topic": "click", "partition": 7},
    ]
}
** Producer
*** 建立生产者发送消息
bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-replicated-test

** Partition
*** 添加partition
/bin/kafka-topics.sh –zookeeper localhost:2181/config/mobile/mq –alter –partitions 20 –topic
topicName
/bin/kafka-topics.sh --zookeeper localhost:2181 /kafka --alter --topic *** --partitions 10

*** 重新分配分区
bin/kafka-reassign-partitions.sh --topics-to-move-json-file topics-to-move.json --broker-list "171" --zookeeper 192.168.197.170:2181,192.168.197.171:2181 --execute
cat topic-to-move.json
{"topics":
  [{"topic": "test2"}],
  "version":1
}

** Consumer
*** 建立消费者接受消息
    bin/kafka-console-consumer.sh --bootstrap-server 10.33.2.228:9090,10.33.2.71:9090,10.33.2.185:9090,10.33.2.91:9090,10.33.2.63:9090 --topic smTopic --from-beginning

*** 删除消费者
bin/kafka-consumer-groups.sh --zookeeper 10.45.130.186:2181,10.45.130.187:2181,10.45.130.189:2181 --delete --group api-exception
你妈的，删不掉，好像是因为没有对应的topic信息。

*** 查看消费者列表
bin/kafka-consumer-groups.sh --list --zookeeper 10.45.130.186:2181,10.45.130.187:2181,10.45.130.189:2181

*** 查看消费者详情
bin/kafka-consumer-groups.sh --describe --zookeeper localhost:2181 --group console-consumer-35398

*** 获取_consumer_offsets的dump
先要设置exclude.internal.topics=false
./bin/kafka-console-consumer.sh --topic _consumer_offsets --zookeeper localhost:2181 --formatter
"kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter"  --consumer.config  config/consumer.properties

*** 消费_consumer_offset主题
#Create consumer config
echo "exclude.internal.topics=false" > /tmp/consumer.config
#Only consume the latest consumer offsets
./kafka-console-consumer.sh --consumer.config /tmp/consumer.config \
--formatter "kafka.coordinator.GroupMetadataManager\$OffsetsMessageFormatter" \
--zookeeper localhost:2181 --topic __consumer_offsets



*** 修改kafka Replication factor副本数量
1.bin/kafka-topics.sh --zookeeper host:port --alter --topic name --replication-factor 3
好像操作较重，不太推荐（试了下不行）
2.bin/kafka-preferred-replica-election.sh --zookeeper localhost:12913/kafka --path-to-json-file topicPartitionList.json

3.使用kafka-reassign-partitions.sh（唯一可用）
bin/kafka-reassign-partitions.sh --zookeeper localhost:2181 --reassignment-json-file test.json --execute




kafka启动时设置JMX环境变量
KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false  -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=$ip" JMX_PORT=9997 bin/kafka-server-start.sh config/server.properties

启动kafka-manager如要设置访问端口，加-Dhttp.port=8080
nohup bin/kafka-manager -Dhttp.port=19000 -Dconfig.file=conf/application.conf  -Dapplication.home=/data/kafka-manager/ &

有时启动会报错，需要删除掉/var/run / \$\{\{app_name\}\}.pid这个鬼文件。

查看kafka打开的连接数
lsof -n  | grep `ps aux | grep kafka  | grep -v grep| grep -v kafka-manager | awk '{print $2}'`  | awk '{print $2}'|sort|uniq -c|sort -nr | awk '{print $1}'
** Connector
   更新
   curl -X PUT -H "Content-Type: application/json" -d @updateConfig.json "http://localhost:8083/connectors/test/config"

   提交
   curl -H "Content-Type: application/json" -X POST -d @maxwell-sink.json  http://localhost:8083/connectors

   删除
   curl -X "DELETE" http://localhost:8083/connectors/test2

   重启task
   curl -H "Content-Type: application/json" -X POST  http://localhost:8083/connectors/test2

   updateConnector
   url中指明 update那个，然后json里面直接包裹配置。

   查看状态信息
   bin/kafka-console-consumer.sh --bootstrap-server 10.33.2.228:9090,10.33.2.71:9090,10.33.2.185:9090,10.33.2.91:9090,10.33.2.63:9090 --topic maxwell-sink-status --from-beginning


   "topics": "estation.db_ez.t_book_parcel,estation.db_ez.t_book_queue,estation.db_ez.t_box_type,estation.db_ez.t_cabinet,estation.db_ez.t_cabinet_type,estation.db_ez.t_config,estation.db_ez.t_config_term_relocate,estation.db_ez.t_external_device,estation.db_ez.t_lock_box,estation.db_ez.t_opt_term,estation.db_ez.t_prop_config,estation.db_ez.t_server_config,estation.db_ez.t_server_route,estation.db_ez.t_server_whitelist,estation.db_ez.t_term,estation.db_ez_log.t_ez_changebox,estation.db_ez_log.t_ez_login_code,estation.db_ez_log.t_ez_remark,estation.db_ez_log.t_ez_term_warn_log",

   {
    "topics": "estation.db_ez.t_book_parcel,estation.db_ez.t_book_queue,estation.db_ez.t_box_type,estation.db_ez.t_cabinet,estation.db_ez.t_cabinet_type,estation.db_ez.t_config,estation.db_ez.t_config_term_relocate,estation.db_ez.t_external_device,estation.db_ez.t_lock_box,estation.db_ez.t_opt_term,estation.db_ez.t_prop_config,estation.db_ez.t_server_config,estation.db_ez.t_server_route,estation.db_ez.t_server_whitelist,estation.db_ez.t_term,estation.db_ez_log.t_ez_changebox,estation.db_ez_log.t_ez_login_code,estation.db_ez_log.t_ez_remark,estation.db_ez_log.t_ez_term_warn_log"
}


   estation.db_ez.t_term,estation.db_ez.t_cabinet,estation.db_ez.t_book_parcel

   有个大问题，有的rowPk是int的，无法直接转String。
